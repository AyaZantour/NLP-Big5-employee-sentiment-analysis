#new code of 13:31 26/12/2025

import os
from dotenv import load_dotenv

os.environ['STREAMLIT_SERVER_ENABLE_STATS'] = 'false'



import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from personality_analyzer import PersonalityAnalyzer
load_dotenv()


# Configuration
st.set_page_config(
    page_title="Glassdoor Sentiment Analyzer",
    page_icon="ðŸ“Š",
    layout="wide"
)

# ============================================
# DEFINE TransformersPipeline CLASS
# (Must match the one used in Kaggle training!)
# ============================================
class TransformersPipeline:
    """Pipeline for sentiment analysis using DistilBERT"""
    def __init__(self, model_path, tokenizer_path, device='cpu'):
        self.device = torch.device(device)
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()
        self.label_map = {0: 'NÃ©gatif', 1: 'Neutre', 2: 'Positif'}

    def predict(self, text):
        """Predict sentiment for a single text"""
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=128,
            return_tensors='pt'
        )

        input_ids = encoding['input_ids'].to(self.device)
        attention_mask = encoding['attention_mask'].to(self.device)

        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]
            prediction = torch.argmax(logits, dim=1).cpu().numpy()[0]

        return prediction, probabilities

# # ============================================
# # LOAD MODEL
# # ============================================
# @st.cache_resource
# def load_model():
#     """Load the trained model (once)"""
#     try:
#         # Try loading directly from model files
#         model_path = 'models/transformers_model'
#         tokenizer_path = 'models/transformers_tokenizer'
        
#         # Add these debug prints to see where Streamlit is looking
#         import os
#         st.write(f"Current directory: {os.getcwd()}")
#         st.write(f"Model path exists: {os.path.exists(model_path)}")
#         st.write(f"Tokenizer path exists: {os.path.exists(tokenizer_path)}")
        
#         # Try with local_files_only=True
#         pipeline = TransformersPipeline(model_path, tokenizer_path, device='cpu')
#         st.success("âœ… ModÃ¨le chargÃ© avec succÃ¨s!")
#         return pipeline
#     except Exception as e:
#         st.error(f"âŒ Erreur de chargement: {e}")
#         st.info("""
#         ðŸ” VÃ©rifiez que vous avez:
#         1. Le dossier `models/transformers_model/` avec les fichiers du modÃ¨le
#         2. Le dossier `models/transformers_tokenizer/` avec les fichiers du tokenizer
#         3. Tous les fichiers extraits du ZIP Kaggle
#         """)
#         return None




# # Load model
model = load_model()







# Replace the load_model() function with this SIMPLE version:

@st.cache_resource
def load_model():
    try:
        # Your HuggingFace model
        from transformers import pipeline
        
        MODEL_ID = "AyaZantour/employee-sentiment-model"
        st.write(f"Loading model: {MODEL_ID}")
        
        # Load from HuggingFace
        pipe = pipeline("text-classification", model=MODEL_ID)
        
        # Return a simple adapter
        class SimpleModel:
            def predict(self, text):
                result = pipe(text)[0]
                # Map labels: adjust based on your model
                if "NEG" in result['label'].upper():
                    return 0, [result['score'], 0.1, 0.1]
                elif "POS" in result['label'].upper():
                    return 2, [0.1, 0.1, result['score']]
                else:
                    return 1, [0.1, result['score'], 0.1]
        
        st.success("âœ… Model loaded from HuggingFace!")
        return SimpleModel()
        
    except Exception as e:
        st.error(f"âŒ Error: {e}")
        return None









# # Load personality model (separate from sentiment model!)
# def load_groq_analyzer():
#     try:
#         analyzer = PersonalityAnalyzer()
#         st.success("âœ… Analyseur de personnalitÃ© Groq chargÃ©!")
#         return analyzer
#     except Exception as e:
#         st.error(f"âŒ Erreur Groq: {e}")
#         st.info("""
#         ðŸ”§ Configuration requise:
#         1. CrÃ©ez un compte gratuit sur console.groq.com
#         2. Obtenez votre clÃ© API
#         3. CrÃ©ez un fichier `.env` avec: GROQ_API_KEY=votre_clÃ©
#         """)
#         return None




def load_groq_analyzer():
    try:
        # FIRST try Streamlit Cloud secrets (for production)
        if 'GROQ_API_KEY' in st.secrets:
            api_key = st.secrets['GROQ_API_KEY']
            st.success("âœ… Using API key from Streamlit Cloud secrets")
        
        # FALLBACK to .env file (for local development)
        else:
            from dotenv import load_dotenv
            import os
            load_dotenv()
            api_key = os.getenv('GROQ_API_KEY')
            if api_key:
                st.success("âœ… Using API key from .env file")
            else:
                st.warning("âš ï¸ No API key found in secrets or .env")
                st.info("""
                ðŸ”§ Configuration required:
                1. For local: Create `.env` with GROQ_API_KEY=your_key
                2. For Streamlit Cloud: Add GROQ_API_KEY in Settings â†’ Secrets
                """)
                return None
        
        # Initialize analyzer with the API key
        # Check if PersonalityAnalyzer accepts api_key parameter
        try:
            analyzer = PersonalityAnalyzer(api_key=api_key)
        except TypeError:
            # If constructor doesn't accept api_key, try setting it differently
            analyzer = PersonalityAnalyzer()
            # Or check personality_analyzer.py for how it expects the key
        
        st.success("âœ… Personality analyzer Groq loaded!")
        return analyzer
        
    except Exception as e:
        st.error(f"âŒ Groq error: {e}")
        return None





groq_analyzer = load_groq_analyzer()
# ============================================
# SIDEBAR
# ============================================
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    st.markdown("**ModÃ¨le:** DistilBERT fine-tuned")
    st.markdown("**PrÃ©cision:** 65%")
    st.markdown("**Classes:** NÃ©gatif ðŸ˜  | Neutre ðŸ˜ | Positif ðŸ˜Š")
    
    st.markdown("---")
    st.markdown("### ðŸ“Š Statistiques")
    st.metric("Avis analysÃ©s", "67,000+")
    st.metric("PrÃ©cision modÃ¨le", "65%")
    
    st.markdown("---")

# ============================================
# MAIN APP
# ============================================
st.title("ðŸŽ¯ Glassdoor Sentiment Analyzer")
st.markdown("### Analyse de sentiment des avis Glassdoor avec Transformer AI")
st.markdown("---")

# Section 1: Single review analysis
st.header("ðŸ” Analyse d'un Avis Unique")
col1, col2 = st.columns([2, 1])

with col1:
    review_text = st.text_area(
        "ðŸ“ Collez votre avis Glassdoor ici:",
        height=150,
        placeholder="Exemple: 'J'adore travailler ici! L'Ã©quipe est gÃ©niale et les avantages sont excellents.'"
    )

with col2:
    st.markdown("### ðŸ’¡ Exemples")
    example = st.selectbox(
        "Choisir un exemple:",
        ["", 
         "Positif: Super entreprise avec une culture incroyable",
         "NÃ©gatif: Management toxique et charge de travail excessive",
         "Neutre: L'entreprise est correcte, rien d'exceptionnel"]
    )
    
    if example:
        if "Positif" in example:
            review_text = "J'adore l'ambiance de travail ici. Les managers sont Ã  l'Ã©coute, les projets sont intÃ©ressants et les collÃ¨gues sont formidables. Les avantages sociaux sont compÃ©titifs et il y a de rÃ©elles opportunitÃ©s d'Ã©volution."
        elif "NÃ©gatif" in example:
            review_text = "Management trÃ¨s hiÃ©rarchique et peu Ã  l'Ã©coute. Charge de travail excessive, souvent jusqu'Ã  20h le soir. Pas d'Ã©quilibre vie pro/perso. La rÃ©munÃ©ration n'est pas Ã  la hauteur des attentes."
        elif "Neutre" in example:
            review_text = "L'entreprise est correcte. Le travail est intÃ©ressant mais rÃ©pÃ©titif. Les collÃ¨gues sont sympas. Les avantages sont standards pour le secteur. Rien d'exceptionnel mais correct."

# Analyze button
if st.button("ðŸš€ Analyser le sentiment", type="primary") and review_text:
    if model:
        with st.spinner("ðŸ”® Analyse en cours..."):
            # Predict
            prediction, probabilities = model.predict(review_text)
            
            # Labels
            sentiment_labels = {0: "NÃ©gatif ðŸ˜ ", 1: "Neutre ðŸ˜", 2: "Positif ðŸ˜Š"}
            sentiment_emojis = {0: "ðŸ˜ ", 1: "ðŸ˜", 2: "ðŸ˜Š"}
            sentiment_colors = {0: "#FF6B6B", 1: "#FFD166", 2: "#06D6A0"}
            
            sentiment = sentiment_labels[prediction]
            emoji = sentiment_emojis[prediction]
            color = sentiment_colors[prediction]
            
            # Display results
            st.markdown("---")
            
            # Main result
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.markdown(f"### {emoji}")
                st.markdown(f"### {sentiment}")
                st.markdown(f"**Confiance:** {probabilities[prediction]*100:.1f}%")
            
            with col_b:
                # Gauge
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=probabilities[prediction]*100,
                    title={'text': "Confiance"},
                    domain={'x': [0, 1], 'y': [0, 1]},
                    gauge={
                        'axis': {'range': [0, 100]},
                        'bar': {'color': color},
                        'steps': [
                            {'range': [0, 33], 'color': "#FF6B6B"},
                            {'range': [33, 66], 'color': "#FFD166"},
                            {'range': [66, 100], 'color': "#06D6A0"}
                        ]
                    }
                ))
                fig.update_layout(height=200, margin=dict(l=10, r=10, t=50, b=10))
                st.plotly_chart(fig, use_container_width=True)
            
            with col_c:
                # Detailed scores
                st.markdown("### ðŸ“Š Scores dÃ©taillÃ©s")
                for i, (label, prob) in enumerate(zip(["NÃ©gatif", "Neutre", "Positif"], probabilities)):
                    progress = int(prob * 100)
                    st.markdown(f"**{label}:** {progress}%")
                    st.progress(progress / 100)
            
            # Bar chart
            st.markdown("### ðŸ“ˆ Distribution des scores")
            fig_bar = px.bar(
                x=["NÃ©gatif", "Neutre", "Positif"],
                y=probabilities * 100,
                color=["NÃ©gatif", "Neutre", "Positif"],
                color_discrete_map={"NÃ©gatif": "#FF6B6B", "Neutre": "#FFD166", "Positif": "#06D6A0"},
                labels={"x": "Sentiment", "y": "ProbabilitÃ© (%)"},
                text=[f"{p*100:.1f}%" for p in probabilities]
            )
            fig_bar.update_traces(textposition='outside')
            fig_bar.update_layout(showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # Details
            with st.expander("ðŸ“‹ DÃ©tails de l'analyse"):
                st.markdown(f"**Avis analysÃ©:**")
                st.info(review_text)
                st.markdown(f"**Longueur:** {len(review_text)} caractÃ¨res")
                st.markdown(f"**Mots:** {len(review_text.split())} mots")
    else:
        st.error("ModÃ¨le non chargÃ©. VÃ©rifiez les fichiers du modÃ¨le.")


# ========== AFTER SENTIMENT RESULTS ==========

# ================= PERSONNALITY ANALYSIS =================

if groq_analyzer and review_text:
    with st.spinner("ðŸ§  Analyse de personnalitÃ© avancÃ©e en cours..."):
        
        personality_result = groq_analyzer.analyze(review_text)

        # SAFETY CHECK
        if not isinstance(personality_result, dict) or "scores" not in personality_result:
            st.error("âŒ Erreur lors de l'analyse de personnalitÃ©.")
        else:
            personality_scores = personality_result["scores"]

            st.markdown("---")
            st.header("ðŸ§  Analyse de PersonnalitÃ© Big Five (AI-Powered)")
            st.caption(f"*Analyse rÃ©alisÃ©e avec Groq ({personality_result.get('model_used', 'LLM')})*")

            cols = st.columns(5)

            for idx, (trait, score) in enumerate(personality_scores.items()):
                with cols[idx]:
                    st.markdown(f"**{trait}**")
                    st.progress(score)
                    st.metric("Score", f"{score*100:.1f}%")

            if personality_result.get("analysis"):
                with st.expander("ðŸ“ Explication de l'analyse"):
                    st.write(personality_result["analysis"])
    # ============================================
    # PERSONALITY-BASED RECOMMENDATION SYSTEM (FIXED)
    # ============================================

# Replace your AI recommendations section with this FIXED version:

# ================= AI-POWERED RECOMMENDATIONS =================

if groq_analyzer and review_text and model:  # Make sure model is loaded
    st.markdown("---")
    st.header("ðŸŽ¯ Recommandations PersonnalisÃ©es (AI-Powered)")
    
    with st.spinner("ðŸ¤– GÃ©nÃ©ration de recommandations intelligentes..."):
        try:
            # Get sentiment prediction first (in case it wasn't done yet)
            if 'prediction' not in locals() or 'probabilities' not in locals():
                prediction, probabilities = model.predict(review_text)
            
            # Get sentiment label
            if prediction == 0:
                sentiment_clean = "NÃ©gatif"
            elif prediction == 1:
                sentiment_clean = "Neutre"
            else:
                sentiment_clean = "Positif"
            
            # Generate AI recommendations
            ai_recommendations = groq_analyzer.generate_recommendations(
                review_text=review_text,
                sentiment=prediction,
                sentiment_confidence=probabilities[prediction],
                personality_scores=personality_scores
            )
            
            if ai_recommendations and len(ai_recommendations) > 0:
                st.success(f"âœ… **{len(ai_recommendations)} actions personnalisÃ©es gÃ©nÃ©rÃ©es**")
                
                # Display recommendations as expandable cards
                for i, rec in enumerate(ai_recommendations, 1):
                    # Priority color coding
                    priority_colors = {
                        "URGENT": "#FF4444",
                        "HAUTE": "#FF9800",
                        "MOYENNE": "#2196F3",
                        "BASSE": "#4CAF50"
                    }
                    
                    priority = rec.get("priority", "MOYENNE")
                    color = priority_colors.get(priority, "#2196F3")
                    
                    # Create expander for each recommendation
                    with st.expander(
                        f"{rec['icon']} **{rec['title']}** â€¢ {priority}", 
                        expanded=(i <= 2)  # First 2 expanded by default
                    ):
                        # Action
                        st.markdown("### ðŸŽ¯ Action Ã  rÃ©aliser")
                        st.info(rec['action'])
                        
                        # Details
                        st.markdown("### ðŸ“ Pourquoi c'est important")
                        st.write(rec['details'])
                        
                        # Timeline and Priority
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown(f"**â° Timeline:** {rec['timeline']}")
                        with col2:
                            st.markdown(f"**ðŸš¦ PrioritÃ©:** `{priority}`")
                        
                        st.markdown("---")
                        
                        # Completion checkbox
                        completed = st.checkbox(
                            "âœ… J'ai rÃ©alisÃ© cette action",
                            key=f"ai_rec_{i}",
                            help="Cochez quand vous avez accompli cette recommandation"
                        )
                        
                        if completed:
                            st.success("ðŸŽ‰ Excellent travail! Passez Ã  la suivante.")
                
                # ===== EXPLANATION SECTION =====
                with st.expander("ðŸ” Comment ces recommandations ont Ã©tÃ© gÃ©nÃ©rÃ©es?"):
                    st.markdown(f"""
                    ### Analyse multicritÃ¨re par IA
                    
                    Ces recommandations ont Ã©tÃ© gÃ©nÃ©rÃ©es par **{groq_analyzer.model}** en analysant:
                    
                    1. **Votre avis complet** ({len(review_text)} caractÃ¨res)
                       - Contenu Ã©motionnel et contexte professionnel
                       - Mots-clÃ©s et expressions spÃ©cifiques
                    
                    2. **Sentiment dÃ©tectÃ©** 
                       - Type: {sentiment_clean}
                       - Confiance: {probabilities[prediction]*100:.1f}%
                    
                    3. **Profil de personnalitÃ© Big Five**
                       - NÃ©vrosisme: {personality_scores.get('NÃ©vrosisme', 0.5):.0%}
                       - Extraversion: {personality_scores.get('Extraversion', 0.5):.0%}
                       - Conscience: {personality_scores.get('Conscience', 0.5):.0%}
                       - AgrÃ©abilitÃ©: {personality_scores.get('AgrÃ©abilitÃ©', 0.5):.0%}
                       - Ouverture: {personality_scores.get('Ouverture', 0.5):.0%}
                    
                    ### Avantages de l'IA vs rÃ¨gles fixes:
                    - âœ… Recommandations contextuelles et nuancÃ©es
                    - âœ… Adaptation au ton et style de votre avis
                    - âœ… Actions concrÃ¨tes et actionnables
                    - âœ… Priorisation intelligente
                    """)
                
                # ===== DOWNLOAD ACTION PLAN =====
                st.markdown("---")
                st.subheader("ðŸ“¥ TÃ©lÃ©charger votre Plan d'Action")
                
                col_a, col_b = st.columns([3, 1])
                
                with col_a:
                    st.write("Exportez vos recommandations en format texte pour les garder sous la main.")
                
                with col_b:
                    # Generate downloadable plan
                    action_plan = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     PLAN D'ACTION PROFESSIONNEL PERSONNALISÃ‰          â•‘
â•‘              GÃ©nÃ©rÃ© par IA (Groq)                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Date: {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“Š PROFIL ANALYSÃ‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Sentiment dominant: {sentiment_clean}
Niveau de confiance: {probabilities[prediction]*100:.1f}%

Traits de personnalitÃ© Big Five:
- NÃ©vrosisme: {personality_scores.get('NÃ©vrosisme', 0.5):.0%}
- Extraversion: {personality_scores.get('Extraversion', 0.5):.0%}
- Conscience: {personality_scores.get('Conscience', 0.5):.0%}
- AgrÃ©abilitÃ©: {personality_scores.get('AgrÃ©abilitÃ©', 0.5):.0%}
- Ouverture: {personality_scores.get('Ouverture', 0.5):.0%}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸŽ¯ RECOMMANDATIONS PERSONNALISÃ‰ES ({len(ai_recommendations)})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
                    
                    for i, rec in enumerate(ai_recommendations, 1):
                        action_plan += f"""
{i}. {rec['icon']} {rec['title'].upper()}
   PrioritÃ©: [{rec['priority']}]
   
   âž¤ Action:
   {rec['action']}
   
   âž¤ DÃ©tails:
   {rec['details']}
   
   âž¤ Timeline: {rec['timeline']}
   
   Status: â˜ Ã€ faire  â˜ En cours  â˜ TerminÃ©
   
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
                    
                    action_plan += f"""

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ’¡ CONSEILS POUR LA MISE EN Å’UVRE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Commencez par les actions URGENTES et HAUTES prioritÃ©s
âœ“ Bloquez du temps dans votre agenda pour chaque action
âœ“ Partagez vos objectifs avec un collÃ¨gue de confiance
âœ“ Mesurez vos progrÃ¨s chaque semaine
âœ“ Ajustez votre plan selon les rÃ©sultats

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“ž RESSOURCES & SUPPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ Manager direct
â€¢ Service RH / DÃ©veloppement professionnel
â€¢ Mentor interne (si disponible)
â€¢ Programme d'aide aux employÃ©s (EAP)
â€¢ Formations en ligne (LinkedIn Learning, Coursera)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Plan gÃ©nÃ©rÃ© par: Glassdoor Sentiment Analyzer
ModÃ¨le IA: {groq_analyzer.model}
âš ï¸  Ã€ adapter selon votre contexte organisationnel

"""
                    
                    st.download_button(
                        label="ðŸ“„ TÃ©lÃ©charger le Plan (.txt)",
                        data=action_plan,
                        file_name=f"plan_action_AI_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                        mime="text/plain",
                        type="secondary"
                    )
                
                # ===== FEEDBACK SECTION =====
                st.markdown("---")
                st.subheader("ðŸ’¬ Ces recommandations vous sont-elles utiles?")
                
                col_x, col_y, col_z = st.columns(3)
                
                with col_x:
                    if st.button("ðŸ‘ TrÃ¨s utiles", use_container_width=True):
                        st.success("Merci! ðŸŽ‰")
                
                with col_y:
                    if st.button("ðŸ˜ Moyennement", use_container_width=True):
                        st.info("Merci pour votre retour.")
                
                with col_z:
                    if st.button("ðŸ‘Ž Pas utiles", use_container_width=True):
                        st.warning("Merci. Nous amÃ©liorons constamment l'IA.")
            
            else:
                st.warning("âš ï¸ Aucune recommandation gÃ©nÃ©rÃ©e. Veuillez rÃ©essayer.")
        
        except Exception as e:
            st.error(f"âŒ Erreur lors de la gÃ©nÃ©ration: {str(e)}")
            st.info("ðŸ’¡ Essayez de reformuler votre avis ou vÃ©rifiez votre connexion internet.")
            
            # Debug info (remove in production)
            import traceback
            with st.expander("ðŸ”§ Debug Info (dÃ©veloppement)"):
                st.code(traceback.format_exc())















# Section 2: About
st.markdown("---")
st.header("â„¹ï¸ Ã€ propos")

with st.expander("ðŸ“– Comment fonctionne cette application?"):
    st.markdown("""
    Cette application utilise un modÃ¨le **Transformer** (DistilBERT) fine-tunÃ© sur des avis Glassdoor.
    
    **Technologies utilisÃ©es:**
    - ðŸ¤– **DistilBERT**: ModÃ¨le de langage prÃ©-entraÃ®nÃ©
    - ðŸŽ¯ **Fine-tuning**: EntraÃ®nÃ© sur +67000 avis Glassdoor
    - ðŸ“Š **Streamlit**: Interface utilisateur interactive
    - ðŸ”¥ **PyTorch**: Backend deep learning
    
    **Processus:**
    1. L'avis est tokenizÃ© (dÃ©coupÃ© en mots/morceaux)
    2. Le modÃ¨le analyse le contexte et les relations entre les mots
    3. Une probabilitÃ© est calculÃ©e pour chaque classe
    4. Le sentiment avec la plus haute probabilitÃ© est sÃ©lectionnÃ©
    """)

with st.expander("âš¡ Performances du modÃ¨le"):
    st.markdown("""
    **MÃ©triques sur le jeu de test:**
    - PrÃ©cision globale: **65%**
    - PrÃ©cision par classe:
      - NÃ©gatif: **73%**
      - Neutre: **60%**
      - Positif: **75%**
    - F1-Score: **0.65**
    """)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ðŸš€ DÃ©veloppÃ© avec Streamlit | ðŸ¤– Powered by Transformer AI</p>
    </div>
    """,
    unsafe_allow_html=True
)